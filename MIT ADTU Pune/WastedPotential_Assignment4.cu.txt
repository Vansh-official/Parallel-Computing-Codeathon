#include <iostream>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <chrono>

using namespace std::chrono;

__global__
void sumGPU(int *a, int *gpu_res, int n) {
  
   __shared__ int c[256];
  
  int index = threadIdx.x + blockIdx.x * blockDim.x;
  int stride = blockDim.x * gridDim.x;
  int cindex = threadIdx.x;
  int temp = 0;

  for(int i = index; i < n * n; i += stride)
    temp += a[i];
  
  c[cindex] = temp;
  __syncthreads();
  int i  = blockDim.x/2;
  
  while(i > 0)
  {
    if(cindex < i)
      c[cindex] += c[cindex + i];
    __syncthreads();
    i/=2;
  }

  if(cindex == 0)   
    atomicAdd(gpu_res, c[0]);
}

void sumCPU(int *a, int *cpu_res, int n)
{
  for(int i = 0; i < n; i++)  
    for(int j = 0; j < n; j++)
      cpu_res[0] += a[(i * n) + j];
  return;
}

bool validate(int *a ,int *b)\
{
  return a[0] == b[0];
}

int main(const int argc, const char** argv) {
  
  int deviceId, numberOfSMs;
  size_t threadsPerBlock, numberOfBlocks;
    
  cudaGetDevice(&deviceId);
  cudaDeviceGetAttribute(&numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId);
  
  threadsPerBlock = 256;
  numberOfBlocks = 32 * numberOfSMs;

  int n = 1000;

  int bytes = n * sizeof(int);
  int *a, *b;
  int *cpu_res, *gpu_res;

  cudaMallocManaged(&a, bytes * bytes);
  cudaMallocManaged(&b, bytes * bytes);  

  cudaMallocManaged(&gpu_res, sizeof(int));
  cudaMallocManaged(&cpu_res, sizeof(int));

  cpu_res[0] = gpu_res[0] = 0;
  
  int *arr[n];
  for (int i = 0; i < n; i++)
  {
    arr[i] = (int*)malloc(bytes);
    for(int j = 0; j < n; j++)
      arr[i][j] = (i * n) + j + 1;
  }
  
  //Implementing 2D array using 1D array
  for(int i = 0; i < n; i++)
    for (int j = 0; j < n; j++)
      a[(i * n) + j] = b[(i * n) + j] = arr[i][j];
    
  cudaMemPrefetchAsync(a, bytes * bytes, deviceId);
  cudaMemPrefetchAsync(gpu_res, sizeof(int), deviceId);
  
  sumGPU<<<numberOfBlocks, threadsPerBlock>>>(a, gpu_res, n);
  cudaDeviceSynchronize();
  
  auto start = high_resolution_clock::now();

  sumCPU(a, cpu_res, n); 
  
  auto stop = high_resolution_clock::now();
  auto t = duration_cast<nanoseconds>(stop - start);
 
  std::cout << "Time taken by CPU: " << t.count() << " nanoseconds" << "\n";

  if(validate(cpu_res, gpu_res))
    printf("Correct\n");
  else
    printf("Wrong\n");

  cudaFree(a);
  cudaFree(b);
  cudaFree(gpu_res);
  cudaFree(cpu_res);
}